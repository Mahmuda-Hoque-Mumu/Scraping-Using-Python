# -*- coding: utf-8 -*-
"""Website Scrape.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CwXjsMIIUI6jzW1iQUsYqRAjgYTt0hA0
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import csv

# Make a request 
page = requests.get(
    "https://realpython.github.io/fake-jobs/")
soup = BeautifulSoup(page.content, 'html.parser')


#store the items into empty list
all_jobs = []

#Scrape the items
jobs= soup.select('div.is-half')
for job in jobs:
  job_title = job.select('h2')[0].text.strip()
  company = job.select('h3')[0].text.strip()
  location = job.select('p')[0].text.strip()
  date = job.select('time')[0].text.strip()
  
  #store the items
  all_jobs.append({
      "Job_title": job_title,
      "Company": company,
      "Location": location,
      "Date": date,
    })

keys = all_jobs[0].keys()


with open('job.csv', 'w', newline='') as output_file:
    dict_writer = csv.DictWriter(output_file, keys)
    print(dict_writer)
    dict_writer.writeheader()
    dict_writer.writerows(all_jobs)